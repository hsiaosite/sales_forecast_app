
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import openai
import os
import matplotlib.pyplot as plt

from prophet import Prophet
from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import train_test_split
from xgboost import plot_importance
st.set_page_config(page_title="é›¶å”®éŠ·å”®é æ¸¬å¹³å°", layout="wide")

# è‡ªè¨‚ CSS ç”¨æ–¼å‡çµæ¨™é¡Œ
st.markdown("""
    <style>
    .sticky-header {
        position: sticky;
        top: 0;
        background-color: white;
        padding: 1rem 0 0.5rem 0;
        z-index: 100;
        border-bottom: 1px solid #ccc;
    }
    </style>
""", unsafe_allow_html=True)

@st.cache_data
def load_data():
    # openai.api_key = os.getenv("OPENAI_API_KEY")
    # streamlitç™¼ä½ˆç¶²ç«™
    openai.api_key = st.secrets["OPENAI_API_KEY"]
    df = pd.read_csv("data/raw/train.csv", parse_dates=["date"])
    holiday_df = pd.read_csv("data/raw/holidays_events.csv", parse_dates=["date"])
    return df,holiday_df

df ,holiday_df = load_data()
df_all = df.copy()
store_options = sorted(df["store_nbr"].unique())

# ğŸ“Œ é è¨­ï¼šä½¿ç”¨è¿‘ä¸‰å¹´è³‡æ–™
cutoff_date = df["date"].max() - pd.DateOffset(years=3)
df = df[df["date"] >= cutoff_date]

# ğŸ“… é æ¸¬èˆ‡åœ–è¡¨å€é–“
horizon_days_map = {"14 å¤©": 14, "3 å€‹æœˆ": 90, "6 å€‹æœˆ": 180}
with st.sidebar:
    st.header("ğŸ”§ æ§åˆ¶é¢æ¿")
    lang = st.radio("ğŸŒ èªè¨€ Language", ["ä¸­æ–‡", "English"], index=0)
    stores = st.multiselect("ğŸª é¸æ“‡åº—é‹ª", store_options, default=[1, 2])
    horizon_label = st.selectbox("ğŸ”® é æ¸¬æœªä¾†å€é–“", list(horizon_days_map.keys()), index=2)

    st.markdown("---")
    st.subheader("ğŸ¤– AI åŠ©ç†æ¨¡å¼")
    ai_mode = st.selectbox("ğŸ”Œ æ¨¡å¼é¸æ“‡", ["é›¢ç·šæ¨¡å¼", "AI æ¨¡å¼"])
    ai_enabled = False
    if ai_mode == "AI æ¨¡å¼":
        password = st.text_input("ğŸ”‘ è«‹è¼¸å…¥å¯†ç¢¼å•Ÿç”¨ AI æ¨¡å¼", type="password")
        if password == "joanna0408demo":
            ai_enabled = True
        else:
            st.warning("å¯†ç¢¼éŒ¯èª¤ï¼ŒAI æ¨¡å¼æœªå•Ÿç”¨")

    
    st.title("ğŸ¤– AI åŠ©ç†")
    if "chat" not in st.session_state:
        st.session_state.chat = []

    if ai_enabled:
        prompt = st.chat_input("é‡å°é æ¸¬çµæœæå•...")

        if prompt:
            st.session_state.chat.append({"role": "user", "content": prompt})
            summary = "\n".join([f"åº—é‹ª {d['store']}: å¹³å‡ {d['mean']:.1f}, ç•°å¸¸ {d['anomalies']}, MAE {d['mae']:.1f}" for d in st.session_state["forecast_info"]])

            with st.spinner("AI åˆ†æä¸­..."):
                try:
                    response = openai.ChatCompletion.create(
                        model="gpt-3.5-turbo",
                        messages=[
                            {"role": "system", "content": f"ä½ æ˜¯ä¸€ä½å°ˆæ¥­é›¶å”®åˆ†æé¡§å•ã€‚ä½¿ç”¨è€…ç›®å‰åˆ†æçš„åº—é‹ªè³‡æ–™å¦‚ä¸‹ï¼š\n{summary}"},
                            *st.session_state.chat
                        ]
                    )
                    reply = response.choices[0].message["content"]
                    st.session_state.chat.append({"role": "assistant", "content": reply})
                except Exception as e:
                    reply = f"â— ç™¼ç”ŸéŒ¯èª¤ï¼š{e}"
                    st.session_state.chat.append({"role": "assistant", "content": reply})

    # ğŸ§  è‡ªå‹• AI å»ºè­°æç¤ºï¼ˆç„¡è¼¸å…¥æ™‚ï¼‰
    if ai_enabled and not prompt and "forecast_info" in st.session_state:
        auto_summary = "\n".join([f"åº—é‹ª {d['store']}: å¹³å‡ {d['mean']:.1f}, MAE {d['mae']:.1f}, ç•°å¸¸å¤©æ•¸ {d['anomalies']}" for d in st.session_state["forecast_info"]])
        auto_prompt = f"ä½ æ˜¯ä¸€ä½å€åŸŸåº—é•·ï¼Œè«‹æ ¹æ“šä»¥ä¸‹è³‡æ–™æå‡º 3 å€‹ç‡Ÿé‹æ”¹å–„å»ºè­°ï¼Œä¾›é«˜å±¤æ±ºç­–åƒè€ƒï¼š\n{auto_summary}"
        with st.spinner("AI è‡ªå‹•åˆ†æä¸­..."):
            try:
                response = openai.ChatCompletion.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": f"ä½ æ˜¯ä¸€ä½é›¶å”®åˆ†æé¡§å•ï¼Œè«‹æ ¹æ“šä»¥ä¸‹è³‡æ–™æå‡ºè§€å¯Ÿé‡é»èˆ‡å»ºè­°ï¼š\n{auto_summary}"},
                        {"role": "user", "content": auto_prompt}
                    ]
                )
                reply = response.choices[0].message["content"]
                st.markdown("### ğŸ¤– è‡ªå‹•å»ºè­°å¡ç‰‡")
                st.info(reply)
            except Exception as e:
                st.warning(f"è‡ªå‹•å»ºè­°ç”¢ç”Ÿå¤±æ•—ï¼š{e}")

    else:
        st.info("ç›®å‰ç‚ºé›¢ç·šæ¨¡å¼ï¼Œåƒ…æä¾›åŸºæœ¬æ‘˜è¦ï¼Œä¸æœƒä½¿ç”¨ OpenAI APIã€‚")

    for msg in st.session_state.chat:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])


horizon_days = horizon_days_map[horizon_label]
chart_start = df["date"].max() - pd.DateOffset(months=6)
chart_end = df["date"].max() + pd.Timedelta(days=horizon_days)

def t(zh, en):
    return zh if lang == "ä¸­æ–‡" else en

# ğŸ“Œ å‡çµæ¨™é¡Œå€
st.title(t("ğŸ“Š é›¶å”®éŠ·å”®é æ¸¬åˆ†æ", "ğŸ“Š Retail Sales Forecast Analysis"))
st.markdown('<div class="sticky-header">', unsafe_allow_html=True)

# ä¸»æ¬„èˆ‡ AI åŠ©ç†æ¬„åˆ†æ¬„
col1, col2  = st.columns(2)
with col1:
    st.markdown(t(
        f"""ğŸ“¦ **åŠŸèƒ½ç‰¹è‰²ï¼š**
- ä½¿ç”¨ Prophet èˆ‡ XGBoost é›™æ¨¡å‹é æ¸¬éŠ·å”®
- è¨“ç·´è³‡æ–™å€é–“ï¼š**{cutoff_date.date()} ~ {df['date'].max().date()}**
- é æ¸¬å€é–“ï¼š**{horizon_label}**
""",
        f"""ğŸ“¦ **Features:**
- Dual models: Prophet & XGBoost
- Training data: {cutoff_date.date()} ~ {df['date'].max().date()}
- Forecast horizon: {horizon_label}
"""
    ))
with col2:
    st.markdown(t(
        """ğŸ“˜ **æŒ‡æ¨™èªªæ˜**ï¼š
- **å¹³å‡éŠ·å”®**ï¼šè§€å¯ŸæœŸé–“æ¯æ—¥å¹³å‡éŠ·å”®ï¼ˆä¸å« 0ï¼‰
- **æ¨™æº–å·®**ï¼šéŠ·å”®æ³¢å‹•ç¨‹åº¦
- **ç•°å¸¸å¤©æ•¸**ï¼šè¶…é Â±3Ïƒ çš„å¤©æ•¸
- **è¶¨å‹¢è©•ä¼°**ï¼šç„¡ç•°å¸¸ç‚ºç©©å®šï¼Œæœ‰ç‚ºæ³¢å‹•
""",
        """ğŸ“˜ **Metric Description**:
- **Average Sales**: Daily mean (excluding 0)
- **Std Dev**: Sales variability
- **Anomaly Days**: Outliers beyond Â±3Ïƒ
- **Trend**: 'Stable' or 'Fluctuating'
"""
    ))
st.markdown('</div>', unsafe_allow_html=True)



# with col3:
# ğŸ“ˆ å¤šåº—é‹ª Prophet æ¯”è¼ƒï¼ˆæå‰ï¼‰
if len(stores) > 1:
    st.subheader("ğŸ“ˆ å¤šåº—é‹ªé æ¸¬æ¯”è¼ƒï¼ˆProphetï¼‰")
    all_prophet_forecast = []
    for store in stores:
        df_store_tmp = df[df["store_nbr"] == store].sort_values("date")
        df_prophet_tmp = df_store_tmp[["date", "sales"]].rename(columns={"date": "ds", "sales": "y"})
        model_tmp = Prophet(daily_seasonality=True)
        model_tmp.fit(df_prophet_tmp)
        future_tmp = model_tmp.make_future_dataframe(periods=horizon_days)
        forecast_tmp = model_tmp.predict(future_tmp)
        forecast_tmp = forecast_tmp[["ds", "yhat"]].rename(columns={"ds": "date", "yhat": "sales"})
        forecast_tmp["store_nbr"] = store
        all_prophet_forecast.append(forecast_tmp)

    merged_prophet = pd.concat(all_prophet_forecast)
    chart_df = merged_prophet[merged_prophet["date"].between(chart_start, chart_end)]
    fig_multi = px.line(chart_df, x="date", y="sales", color="store_nbr", title="å„åº—é‹ª Prophet é æ¸¬æ¯”è¼ƒ")
    st.plotly_chart(fig_multi, use_container_width=True)

summary_lines = []

# æ¨¡æ“¬æ¯å®¶åº—é‹ªçš„ç›®å‰åº«å­˜é‡ï¼ˆå¯æ”¹ç‚ºå¯¦éš›è®€å–è³‡æ–™ï¼‰
mock_inventory = {store: np.random.randint(300, 1000) for store in stores}

all_prophet_forecast = []
all_forecast_info = []

# with col2:
for store in stores:
    st.subheader(t(f"ğŸª åº—é‹ª {store}", f"ğŸª Store {store}"))
    df_store = df[df["store_nbr"] == store].sort_values("date")
    df_store_nz = df_store[df_store["sales"] > 0]
    df_prophet = df_store[["date", "sales"]].rename(columns={"date": "ds", "sales": "y"})

    # Prophet
    model_p = Prophet(daily_seasonality=True)
    model_p.fit(df_prophet)
    future = model_p.make_future_dataframe(periods=horizon_days)
    forecast = model_p.predict(future)
    forecast_prophet = forecast[["ds", "yhat"]].rename(columns={"ds": "date", "yhat": "sales"})
    forecast_prophet["model"] = "Prophet"
    forecast_prophet["store_nbr"] = store
    all_prophet_forecast.append(forecast_prophet)

    # Prophet MAE
    df_actual = df_all[df_all["store_nbr"] == store]
    merged = pd.merge(forecast_prophet, df_actual, on="date", how="inner")
    prophet_mae = mean_absolute_error(merged["sales_y"], merged["sales_x"]) if not merged.empty else np.nan

    # XGBoost
    df_xgb = df_store.copy()
    df_xgb["dayofweek"] = df_xgb["date"].dt.dayofweek
    df_xgb["month"] = df_xgb["date"].dt.month
    df_xgb["day"] = df_xgb["date"].dt.day
    df_xgb["year"] = df_xgb["date"].dt.year
    df_xgb["store_nbr"] = store
    X = df_xgb[["dayofweek", "month", "day", "year", "store_nbr"]]
    y = df_xgb["sales"]
    X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size=0.2)
    model_x = XGBRegressor(n_estimators=100, max_depth=3)
    model_x.fit(X_train, y_train)
    y_pred = model_x.predict(X_test)

    xgb_result = pd.DataFrame({
        "date": df_xgb.loc[X_test.index, "date"],
        "sales": y_pred,
        "model": "XGBoost"
    })

    # Combine
    combined = pd.concat([
        forecast_prophet[forecast_prophet["date"].between(chart_start, chart_end)],
        xgb_result[xgb_result["date"].between(chart_start, chart_end)]
    ])

    fig = px.line(combined, x="date", y="sales", color="model",
                title=t(f"åº—é‹ª {store} - éŠ·å”®é æ¸¬æ¯”è¼ƒ", f"Store {store} - Forecast Comparison"))
    st.plotly_chart(fig, use_container_width=True)

    xgb_mae = mean_absolute_error(y_test, y_pred)
    df_summary = pd.DataFrame({
        "æ¨¡å‹": ["Prophet", "XGBoost"],
        "å¹³å‡é æ¸¬": [forecast_prophet["sales"].mean(), xgb_result["sales"].mean()],
        "MAE": [prophet_mae, xgb_mae]
    })
    st.dataframe(df_summary)

    # ğŸ“Š ç‡Ÿé‹ç‹€æ³æ‘˜è¦
    observed = df_store_nz[df_store_nz["date"].between(chart_start, chart_end)]
    mean_sales = observed["sales"].mean()
    std_sales = observed["sales"].std()
    anomalies = observed[np.abs(observed["sales"] - mean_sales) > 3 * std_sales]
    anomaly_days = len(anomalies)
    trend = t("ç©©å®š", "Stable") if anomaly_days == 0 else t("æ³¢å‹•", "Fluctuating")
    summary_text = f"ğŸª åº—é‹ª {store}ï¼šå¹³å‡éŠ·å”® {mean_sales:.1f}ï¼Œæ¨™æº–å·® {std_sales:.1f}ï¼Œç•°å¸¸å¤©æ•¸ {anomaly_days}ï¼Œè¶¨å‹¢è©•ä¼°ï¼š{trend}ï¼ŒMAE èª¤å·®ï¼š{xgb_mae}"

    # ğŸ“¦ åº«å­˜æé†’èˆ‡è£œè²¨å»ºè­°
    forecast_period = forecast_prophet.tail(horizon_days)
    total_forecast = forecast_period["sales"].sum()
    inventory = mock_inventory[store]
    safety_factor = 1.1  # å®‰å…¨ä¿‚æ•¸ 10%
    reorder_qty = max(int(total_forecast * safety_factor - inventory), 0)

    if inventory < total_forecast:
        st.error(f"âš ï¸ åº—é‹ª {store} çš„é æ¸¬éŠ·å”®ç¸½é‡ç‚º {total_forecast:.0f}ï¼Œç›®å‰åº«å­˜åƒ… {inventory}ï¼Œå¯èƒ½æœƒç™¼ç”Ÿç¼ºè²¨ï¼")
        if reorder_qty > 0:
            st.info(f"ğŸ”„ å»ºè­°è£œè²¨ç´„ {reorder_qty} å–®ä½ï¼ˆå« 10% å®‰å…¨ä¿‚æ•¸ï¼‰")
    else:
        st.success(f"âœ… åº—é‹ª {store} åº«å­˜é‡è¶³å¤ ï¼ˆé æ¸¬éœ€æ±‚ï¼š{total_forecast:.0f}ï¼Œåº«å­˜ï¼š{inventory}ï¼‰")

    st.markdown("#### ğŸ“Š " + t("ç‡Ÿé‹ç‹€æ³æ‘˜è¦", "Operational Summary"))
    st.markdown(summary_text)

    # ç•°å¸¸åµæ¸¬ ğŸ“‰ ç•°å¸¸éŠ·å”®æ—¥åˆ†æ
    st.subheader("ğŸ“‰ ç•°å¸¸éŠ·å”®æ—¥åˆ†æ")
    anomaly_report = []
    for store in stores:
        df_store = df[df["store_nbr"] == store].sort_values("date")
        mean_sales = df_store['sales'].mean()
        std_sales = df_store['sales'].std()
        upper = mean_sales + 3 * std_sales
        lower = mean_sales - 3 * std_sales
        anomalies = df_store[(df_store['sales'] > upper) | (df_store['sales'] < lower)]
        for _, row in anomalies.iterrows():
            is_holiday = row['date'] in holiday_df['date'].values
            reason = "ç¯€æ—¥å½±éŸ¿" if is_holiday else "å¯èƒ½ç•°å¸¸æ³¢å‹•"
            anomaly_report.append({
                'åº—é‹ª': store,
                'æ—¥æœŸ': row['date'].date(),
                'éŠ·å”®é¡': row['sales'],
                'ç•°å¸¸åŸå› ': reason
            })
    # é¡¯ç¤ºç•°å¸¸å ±å‘Š
    if anomaly_report:
        st.dataframe(pd.DataFrame(anomaly_report))
    else:
        st.info("ç„¡æ˜é¡¯ç•°å¸¸éŠ·å”®ç´€éŒ„ã€‚")
        
    # æä¾›çµ¦ AI åŠ©ç†å­˜å–
    all_forecast_info.append({
            "store": store,
            "mean": mean_sales,
            "std": std_sales,
            "anomalies": anomaly_days,
            "trend": trend,
            "mae": xgb_mae
        })
    st.session_state["forecast_info"] = all_forecast_info


# ğŸ“Š é æ¸¬æ¨¡å‹èˆ‡å¯¦éš›éŠ·å”®ç¸½è¡¨æ ¼æ¯”è¼ƒ
compare_records = []

for store in stores:
    df_store = df_all[df_all["store_nbr"] == store].sort_values("date")
    actual_period = df_store[df_store["date"].between(chart_start, chart_end)]
    prophet_period = all_prophet_forecast[stores.index(store)].copy()
    prophet_period = prophet_period[prophet_period["date"].between(chart_start, chart_end)]

    df_prophet_avg = prophet_period["sales"].mean()
    df_actual_avg = actual_period["sales"].mean()

    # XGBoost é æ¸¬è³‡æ–™ï¼ˆå¾ all_forecast_info ä¸­æ‰¾ MAEï¼‰
    match = [d["mae"] for d in all_forecast_info if d["store"] == store]
    xgb_mae = round(match[0], 2) if match else np.nan

    compare_records.append({
        "åº—é‹ª": store,
        "å¯¦éš›å¹³å‡éŠ·å”®": round(df_actual_avg, 1),
        "Prophet é æ¸¬å¹³å‡": round(df_prophet_avg, 1),
        "XGBoost MAE": round(xgb_mae, 2)
    })

df_compare = pd.DataFrame(compare_records)
st.subheader("ğŸ“Š é æ¸¬æ¨¡å‹ vs å¯¦éš›å¹³å‡éŠ·å”®ç¸½è¡¨")
st.dataframe(df_compare)


reorder_report = []

# ğŸ“Œ å½™æ•´æ‰€æœ‰è£œè²¨å»ºè­°
for store in stores:
    forecast_period = all_prophet_forecast[stores.index(store)].tail(horizon_days)
    total_forecast = forecast_period["sales"].sum()
    inventory = mock_inventory[store]
    safety_factor = 1.1
    reorder_qty = max(int(total_forecast * safety_factor - inventory), 0)

    reorder_report.append({
        "åº—é‹ª": store,
        "é æ¸¬éœ€æ±‚é‡": int(total_forecast),
        "ç›®å‰åº«å­˜": inventory,
        "å»ºè­°è£œè²¨é‡": reorder_qty
    })

# åŒ¯å‡ºæŒ‰éˆ•
reorder_df = pd.DataFrame(reorder_report)
st.download_button(
    label="ğŸ“¤ ä¸‹è¼‰è£œè²¨å»ºè­°æ¸…å–® (CSV)",
    data=reorder_df.to_csv(index=False).encode("utf-8-sig"),
    file_name="reorder_suggestions.csv",
    mime="text/csv"
)
  
